# tools/augment_aliases.py
from __future__ import annotations
import argparse, time, json
from pathlib import Path
from collections import Counter, defaultdict

import pandas as pd
from tqdm import tqdm

from kiwoom_finance.dart_client import init_dart, find_corp, extract_fs
from kiwoom_finance.preprocess import preprocess_all
from kiwoom_finance.aliases import _normalize_name, KOR_KEY_ALIASES, CF_KEY_ALIASES

# ---------- 1) ì•ˆì „/ìœ„í—˜ í‚¤ ê·œì¹™ ----------
AUTO_ALLOW_SAFE_KEYS = {
    # BS ë³´ì¡°
    "í˜„ê¸ˆë°í˜„ê¸ˆì„±ìì‚°","ê¸°íƒ€ìœ ë™ìì‚°","ê¸°íƒ€ë¹„ìœ ë™ìì‚°","ê¸°íƒ€ìœ ë™ë¶€ì±„","ê¸°íƒ€ë¹„ìœ ë™ë¶€ì±„",
    "ë¦¬ìŠ¤ë¶€ì±„","ìœ í˜•ìì‚°","ë¬´í˜•ìì‚°",
    # CF ë³´ì¡°
    "íˆ¬ìí™œë™í˜„ê¸ˆíë¦„","ì¬ë¬´í™œë™í˜„ê¸ˆíë¦„","ìœ í˜•ìì‚°ì˜ì·¨ë“","ìœ í˜•ìì‚°ì˜ì²˜ë¶„","ë¬´í˜•ìì‚°ì˜ì·¨ë“","ë¬´í˜•ìì‚°ì˜ì²˜ë¶„",
    "ê¸°ì´ˆí˜„ê¸ˆë°í˜„ê¸ˆì„±ìì‚°","ê¸°ë§í˜„ê¸ˆë°í˜„ê¸ˆì„±ìì‚°","ì´ìì˜ì§€ê¸‰",
}

REVIEW_ONLY_KEYS = {
    # IS í•µì‹¬
    "ë§¤ì¶œì•¡","ìˆ˜ìµ","ì˜ì—…ìˆ˜ìµ","ì˜ì—…ì´ìµ","ë‹¹ê¸°ìˆœì´ìµ",
    # ìë³¸ í•µì‹¬
    "ìë³¸ê¸ˆ","ì´ìµì‰ì—¬ê¸ˆ",
}

# ---------- 2) ì—°ê²°â†’ë³„ë„ ìë™ í´ë°± ----------
def get_fs_with_fallback(corp, bgn_de, report_tp, separate=True):
    try:
        return extract_fs(corp, bgn_de=bgn_de, report_tp=report_tp, separate=separate)
    except Exception as e:
        from dart_fss.errors.errors import NotFoundConsolidated
        is_nfc = isinstance(e, NotFoundConsolidated) or "NotFoundConsolidated" in f"{type(e)} {e}"
        if is_nfc:
            alt = not separate
            tqdm.write(f"ğŸ” [{getattr(corp,'stock_code','?')}] ì—°ê²°/ë³„ë„ ë¯¸ë°œê²¬ â†’ {'ë³„ë„' if alt else 'ì—°ê²°'} ì¬ì‹œë„")
            return extract_fs(corp, bgn_de=bgn_de, report_tp=report_tp, separate=alt)
        raise

# ---------- 3) ìˆ˜ì§‘ ----------
def scan_codes_for_aliases(codes, bgn_de, report_tp, separate, throttle, limit=None):
    counter = Counter()
    examples = defaultdict(list)

    it = codes[:limit] if limit else codes
    pbar = tqdm(total=len(it), ncols=100, desc="ğŸ” ìŠ¤ìº”", dynamic_ncols=False)
    for code in it:
        try:
            time.sleep(throttle)
            corp = find_corp(code)
            fs = get_fs_with_fallback(corp, bgn_de=bgn_de, report_tp=report_tp, separate=separate)
            bs, is_, cis, cf = preprocess_all(fs)
            for df in (bs, is_, cis, cf):
                if df is None or df.empty:
                    continue
                for c in df.columns:
                    norm = _normalize_name(c)
                    counter[norm] += 1
                    if len(examples[norm]) < 5 and c not in examples[norm]:
                        examples[norm].append(c)
            pbar.set_postfix(ok=code)
        except Exception as e:
            pbar.set_postfix(err=f"{code}:{type(e).__name__}")
        finally:
            pbar.update(1)
    pbar.close()
    return counter, examples

# ---------- 4) ì•ˆì „ ìë™ì¶”ê°€ & ê²€í†  í ----------
def split_safe_and_review(counter, examples):
    known = set()
    for v in KOR_KEY_ALIASES.values():
        known.update(v)
    known_norm = {_normalize_name(x) for x in known if x}

    safe_rows, review_rows = [], []

    for norm, cnt in counter.most_common():
        # ì´ë¯¸ ë“±ë¡ë¨ â†’ ìŠ¤í‚µ
        if norm in known_norm:
            continue
        # ì›í˜• ì˜ˆì‹œ
        sample = examples.get(norm, [])
        original = sample[0] if sample else norm

        # ì›í˜•(ê³µë°±/ê¸°í˜¸ ì œì™¸)ì´ ìë™ í—ˆìš© ë¦¬ìŠ¤íŠ¸ ì¤‘ í•˜ë‚˜ì¸ê°€?
        # NOTE: ì›í˜•ì„ ê·¸ëŒ€ë¡œ ë¹„êµí•  ë•Œë„ normalize ì—†ì´ íŒë‹¨ì´ í•„ìš”í•œ í•­ëª©ì´ë¼ originalë„ í•¨ê»˜ ì²´í¬
        # (ì˜ˆ: "ê¸°íƒ€ ìœ ë™ë¶€ì±„" vs "ê¸°íƒ€ìœ ë™ë¶€ì±„")
        base = original.replace(" ", "").replace("Â·","").replace(",","").replace("(","").replace(")","").replace("/","").replace("-","")

        if base in AUTO_ALLOW_SAFE_KEYS and base not in REVIEW_ONLY_KEYS:
            safe_rows.append((norm, cnt, " | ".join(sample[:5])))
        else:
            review_rows.append((norm, cnt, " | ".join(sample[:5])))

    safe_df = pd.DataFrame(safe_rows, columns=["normalized_name","count","examples"])
    review_df = pd.DataFrame(review_rows, columns=["normalized_name","count","examples"])
    return safe_df, review_df

# ---------- 5) ë°˜ì˜ ë¡œì§(ë©”ëª¨ë¦¬ ìƒ) ----------
def apply_safe_to_aliases(safe_df):
    # ì—¬ê¸°ì„œëŠ” ëŒ€í‘œì ìœ¼ë¡œ BS/CFì—ì„œ ë§ì´ ì“°ëŠ” ê³³ì— ì¶”ê°€
    # í•„ìš”ì‹œ ë” ì´˜ì´˜íˆ ë§¤í•‘ ê·œì¹™ ì¶”ê°€
    adds = defaultdict(list)

    for _, row in safe_df.iterrows():
        name = row["normalized_name"]
        # ëŒ€í‘œ í‚¤êµ°ì— ê·€ì†
        if name in {"í˜„ê¸ˆë°í˜„ê¸ˆì„±ìì‚°"}:
            adds["current_assets"].append("í˜„ê¸ˆë°í˜„ê¸ˆì„±ìì‚°")
        elif name in {"ê¸°íƒ€ìœ ë™ìì‚°"}:
            adds["current_assets"].append("ê¸°íƒ€ìœ ë™ìì‚°")
        elif name in {"ê¸°íƒ€ë¹„ìœ ë™ìì‚°","ìœ í˜•ìì‚°","ë¬´í˜•ìì‚°"}:
            # ì´ìì‚° ì§ì ‘í•©ì‚°ì€ ìœ„í—˜í•  ìˆ˜ ìˆì–´ â€œì°¸ì¡°ìš©â€ìœ¼ë¡œë§Œ ì¶”ê°€í•˜ê³  ì‹¤ì œ ê³„ì‚°ì—” ì•ˆ ì”€
            pass
        elif name in {"ê¸°íƒ€ìœ ë™ë¶€ì±„"}:
            adds["current_liabilities"].append("ê¸°íƒ€ìœ ë™ë¶€ì±„")
        elif name in {"ê¸°íƒ€ë¹„ìœ ë™ë¶€ì±„","ë¦¬ìŠ¤ë¶€ì±„"}:
            # ì°¨ì…/ë¶€ì±„ ì§‘ê³„ì— ë„ì›€
            pass
        # CF ê³„ì •
        elif name in {"íˆ¬ìí™œë™í˜„ê¸ˆíë¦„","ì¬ë¬´í™œë™í˜„ê¸ˆíë¦„"}:
            # ì´í˜„ê¸ˆíë¦„ ì§‘ê³„ì—ëŠ” ì§ì ‘ ì•ˆ ì“°ë‹ˆ ì°¸ê³ ë§Œ
            pass
        elif name in {"ìœ í˜•ìì‚°ì˜ì·¨ë“","ë¬´í˜•ìì‚°ì˜ì·¨ë“"}:
            CF_KEY_ALIASES.setdefault("capex", [])
            if "ìœ í˜•ìì‚°ì˜ ì·¨ë“" not in CF_KEY_ALIASES["capex"]:
                CF_KEY_ALIASES["capex"].extend(["ìœ í˜•ìì‚°ì˜ ì·¨ë“","ìœ í˜•ìì‚°ì˜ì·¨ë“"])
            if "ë¬´í˜•ìì‚°ì˜ ì·¨ë“" not in CF_KEY_ALIASES["capex"]:
                CF_KEY_ALIASES["capex"].extend(["ë¬´í˜•ìì‚°ì˜ ì·¨ë“","ë¬´í˜•ìì‚°ì˜ì·¨ë“"])
        elif name in {"ìœ í˜•ìì‚°ì˜ì²˜ë¶„","ë¬´í˜•ìì‚°ì˜ì²˜ë¶„","ì´ìì˜ì§€ê¸‰","ê¸°ì´ˆí˜„ê¸ˆë°í˜„ê¸ˆì„±ìì‚°","ê¸°ë§í˜„ê¸ˆë°í˜„ê¸ˆì„±ìì‚°"}:
            # ë³´ê³ /ê²€ì¦ìš© ì°¸ì¡°ì— í™œìš©
            pass

    # KOR_KEY_ALIASESì— ë°˜ì˜
    for key, vals in adds.items():
        cur = KOR_KEY_ALIASES.get(key, [])
        merged = list(dict.fromkeys(cur + vals))
        KOR_KEY_ALIASES[key] = merged

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--api-key", default=None)
    ap.add_argument("--bgn-de", default="20210101")
    ap.add_argument("--report-tp", choices=["annual","quarter"], default="annual")
    ap.add_argument("--separate", action="store_true", help="ì—°ê²° ëŒ€ì‹  ë³„ë„ ìš°ì„ ")
    ap.add_argument("--limit", type=int, default=None)
    ap.add_argument("--throttle", type=float, default=0.6)
    ap.add_argument("--autosave-every", type=int, default=100)
    ap.add_argument("--codes", nargs="*", default=[])
    args = ap.parse_args()

    init_dart(args.api_key)

    # ê¸°ë³¸ ìƒ˜í”Œ ì—†ìœ¼ë©´ ìƒìœ„ì—ì„œ ë‚´ë ¤ì˜¨ ì½”ë“œ ëª©ë¡ ë˜ëŠ” ì¼ë¶€ ëŒ€í˜•ì£¼ ìƒ˜í”Œ
    SAMPLE = args.codes or ["005930","000660","035420","051910","207940","000270","068270","035720","034220","000720"]

    t0 = time.time()
    counter, examples = scan_codes_for_aliases(
        SAMPLE, bgn_de=args.bgn_de, report_tp=args.report_tp, separate=args.separate,
        throttle=args.throttle, limit=args.limit
    )

    safe_df, review_df = split_safe_and_review(counter, examples)
    apply_safe_to_aliases(safe_df)  # ë©”ëª¨ë¦¬ ìƒ ë°˜ì˜

    # ì €ì¥
    project_root = Path(__file__).resolve().parents[1]
    out_dir = project_root / "artifacts"
    out_dir.mkdir(parents=True, exist_ok=True)

    safe_path   = out_dir / "aliases_auto_added_preview.json"
    review_path = out_dir / "aliases_review_queue.csv"

    # í˜„ì¬ ë©”ëª¨ë¦¬ìƒì˜ ë³´ê°•ëœ KOR_KEY_ALIASES/CF_KEY_ALIASES ë¯¸ë¦¬ë³´ê¸° ì €ì¥(ì ìš©ì€ ìˆ˜ë™ ë°˜ì˜)
    preview = {
        "KOR_KEY_ALIASES_preview": KOR_KEY_ALIASES,
        "CF_KEY_ALIASES_preview": CF_KEY_ALIASES,
        "auto_added_candidates": safe_df.to_dict(orient="records"),
    }
    safe_path.write_text(json.dumps(preview, ensure_ascii=False, indent=2), encoding="utf-8")
    review_df.to_csv(review_path.as_posix(), index=False, encoding="utf-8-sig")

    elapsed = time.time() - t0
    print(f"\nğŸ“ ìë™ì¶”ê°€ í”„ë¦¬ë·°: {safe_path}")
    print(f"ğŸ“ ê²€í†  ëŒ€ê¸°ì—´ CSV: {review_path}")
    print(f"â±ï¸ ê²½ê³¼ì‹œê°„: {elapsed:.1f}s | ìˆ˜ì§‘ distinct í›„ë³´: {len(counter)}ê°œ | ì•ˆì „ ìë™ì¶”ê°€: {len(safe_df)}ê°œ | ê²€í† ëŒ€ìƒ: {len(review_df)}ê°œ")

if __name__ == "__main__":
    main()
