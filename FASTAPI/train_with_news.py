# ================================
# train_with_news.py (ìë™ í•™ìŠµ + ëª¨ë¸ ì €ì¥)
# ================================
import os
import time
import html
import requests
import pandas as pd
import numpy as np
from datetime import datetime, timezone
from urllib.parse import urlparse
from typing import List, Dict, Tuple
from dotenv import load_dotenv

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, classification_report
import xgboost as xgb
import joblib

# ----------- ì„¤ì • -----------
COMPANY_COL = "company_name"
TARGET_COL = "credit_ratings"

# ----------- ìœ í‹¸ í•¨ìˆ˜ -----------
def clean_text(t):
    if not t:
        return ""
    return html.unescape(t.replace("<b>", "").replace("</b>", "").strip())

def parse_pubdate(pubdate_str):
    try:
        return datetime.strptime(pubdate_str, "%a, %d %b %Y %H:%M:%S %z")
    except Exception:
        return datetime.now(timezone.utc)

def recency_weight(pub_dt, now):
    delta_days = max(0.0, (now - pub_dt).total_seconds() / 86400.0)
    return 0.5 ** (delta_days / 15.0)

def source_weight(host):
    return 1.0

def weighted_aggregate(results, weights):
    if not results: 
        return {"POSITIVE":0,"NEGATIVE":0,"NEUTRAL":0}
    w = np.clip(np.array(weights), 1e-6, None)
    pos = np.average([r["POSITIVE"] for r in results], weights=w)
    neg = np.average([r["NEGATIVE"] for r in results], weights=w)
    neu = np.average([r["NEUTRAL"] for r in results], weights=w)
    return {"POSITIVE": round(pos,4), "NEGATIVE": round(neg,4), "NEUTRAL": round(neu,4)}

def credit_signal(score):
    return round(100.0 * (score.get("POSITIVE",0) - score.get("NEGATIVE",0)), 2)


# ----------- ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸ -----------
def train_and_eval(train_df: pd.DataFrame, target_col: str = TARGET_COL):
    """
    ë‰´ìŠ¤ ê¸°ë°˜ í”¼ì²˜ë¡œ XGBoost ì‹ ìš©ë“±ê¸‰ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ
    """
    # ğŸ”¹ í•™ìŠµì— ì‚¬ìš©í•  í”¼ì²˜ ëª©ë¡ (ë‰´ìŠ¤ ê¸°ë°˜)
    features = [
        "news_sentiment_score",
        "news_count",
        "positive_ratio",
        "negative_ratio",
        "sentiment_volatility",
        "recency_weight_mean"
    ]

    # ë°ì´í„° ìœ íš¨ì„± ê²€ì¦
    for f in features:
        if f not in train_df.columns:
            raise ValueError(f"í•„ìš”í•œ í”¼ì²˜ '{f}'ê°€ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤. stock_augmented.xlsxë¥¼ í™•ì¸í•˜ì„¸ìš”.")

    if target_col not in train_df.columns:
        raise ValueError(f"íƒ€ê¹ƒ ì—´ '{target_col}'ì´ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.")

    y = train_df[target_col]
    X = train_df[features]
    feature_cols = X.columns  # ğŸ”¹ í•™ìŠµì— ì‚¬ìš©ëœ ì»¬ëŸ¼ëª… ì €ì¥

    # íƒ€ê¹ƒ ì¸ì½”ë”©
    le = LabelEncoder()
    y_enc = le.fit_transform(y)

    # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„ë¦¬ (ë¼ë²¨ì´ 1ê°œì¸ ê²½ìš° ì˜ˆì™¸ì²˜ë¦¬)
    try:
        X_train, X_test, y_train, y_test = train_test_split(
            X, y_enc, test_size=0.2, random_state=42, stratify=y_enc
        )
    except ValueError as e:
        print(f"[WARN] stratify ë¶ˆê°€: {e}")
        X_train, X_test, y_train, y_test = train_test_split(
            X, y_enc, test_size=0.2, random_state=42
        )

    # XGBoost ëª¨ë¸ ì •ì˜
    model = xgb.XGBClassifier(
        objective="multi:softmax",
        num_class=len(le.classes_),
        eval_metric="mlogloss",
        use_label_encoder=False,
        random_state=42
    )

    # ëª¨ë¸ í•™ìŠµ
    print("\n--- XGBoost ëª¨ë¸ í•™ìŠµ ì¤‘ ---")
    model.fit(X_train, y_train)
    print("--- í•™ìŠµ ì™„ë£Œ ---")

    # í‰ê°€
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    print(f"\nâœ… ëª¨ë¸ ì •í™•ë„: {acc * 100:.2f}%")
    print("\n--- ìƒì„¸ í‰ê°€ ë¦¬í¬íŠ¸ ---")
    print(classification_report(y_test, y_pred, target_names=le.classes_))

    return model, le, feature_cols


def main(train_path="stock_augmented.xlsx"):
    load_dotenv()

    # ê²½ë¡œ í™•ì¸
    if not os.path.exists(train_path):
        raise FileNotFoundError(f"{train_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # ë°ì´í„° ë¡œë“œ
    if train_path.endswith(".xlsx"):
        df = pd.read_excel(train_path)
    else:
        df = pd.read_csv(train_path)

    print(f"ğŸ“Š ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {df.shape[0]}ê°œ ìƒ˜í”Œ, {df.shape[1]}ê°œ ì»¬ëŸ¼")

    # ëª¨ë¸ í•™ìŠµ
    model, le, feature_cols = train_and_eval(df)

    # ëª¨ë¸ ì €ì¥
    joblib.dump(model, "xgb_credit_model.pkl")
    joblib.dump(le, "label_encoder.pkl")
    joblib.dump(feature_cols, "xgb_feature_columns.pkl")

    print("\nâœ… ëª¨ë¸ ë° feature ì»¬ëŸ¼ ì €ì¥ ì™„ë£Œ:")
    print(" - xgb_credit_model.pkl")
    print(" - label_encoder.pkl")
    print(" - xgb_feature_columns.pkl")


if __name__ == "__main__":
    main()
